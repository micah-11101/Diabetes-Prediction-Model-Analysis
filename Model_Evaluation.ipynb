{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Function to record performance metrics to a CSV\n",
    "def log_results_to_csv(model_name, hyperparameters, accuracy, confusion_matrix, classification_report, importances, filename='f_model_eval_log.csv'):\n",
    "    results = {\n",
    "        'Model': model_name,\n",
    "        'Hyperparameters': str(hyperparameters),\n",
    "        'Accuracy': accuracy,\n",
    "        'Confusion Matrix': str(confusion_matrix),\n",
    "        'Classification Report': str(classification_report),\n",
    "        'Feature Importances': str(importances)\n",
    "    }\n",
    "    # Convert to DataFrame and append\n",
    "    results_df = pd.DataFrame([results])\n",
    "    \n",
    "    try:\n",
    "        results_df.to_csv(filename, mode='a', header=False, index=False)\n",
    "    except FileNotFoundError:\n",
    "        # If file doesn't exist, create it with headers\n",
    "        results_df.to_csv(filename, mode='w', header=True, index=False)\n",
    "\n",
    "# Load the diabetes dataset\n",
    "engine = create_engine('sqlite:///diabetesData.db')\n",
    "diabetes_df = pd.read_sql_query('select * from diabetes', con=engine)\n",
    "\n",
    "# Define features set and target vector\n",
    "X = diabetes_df.drop(\"diabetes\", axis=1)\n",
    "y = diabetes_df[\"diabetes\"].to_numpy()\n",
    "\n",
    "# Splitting into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n",
    "# Standard scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model 1: Initial Random Forest Classifier (Baseline Model) ---\n",
    "rf_model = RandomForestClassifier(n_estimators=500, random_state=78)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions and evaluate model\n",
    "predictions = rf_model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "classification_rep = classification_report(y_test, predictions)\n",
    "\n",
    "# Feature importances\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# Log results for the baseline model to csv\n",
    "log_results_to_csv('RandomForestClassifier', {'n_estimators': 500}, accuracy, cm_df, classification_rep, importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model 2: Logistic Regression ---\n",
    "lr_model = LogisticRegression(random_state=78)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions and evaluate model\n",
    "predictions_lr = lr_model.predict(X_test_scaled)\n",
    "accuracy_lr = accuracy_score(y_test, predictions_lr)\n",
    "cm_lr = confusion_matrix(y_test, predictions_lr)\n",
    "cm_df_lr = pd.DataFrame(cm_lr, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "classification_rep_lr = classification_report(y_test, predictions_lr)\n",
    "\n",
    "# Log results for the Logistic Regression model to csv\n",
    "log_results_to_csv('LogisticRegression', {'solver': 'lbfgs'}, accuracy_lr, cm_df_lr, classification_rep_lr, None)\n",
    "\n",
    "# --- Model 2.5: Optimized Logistic Regression ---\n",
    "\n",
    "# Hyperparameter grid for LogisticRegression\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'lbfgs']\n",
    "}\n",
    "\n",
    "# GridSearchCV for LogisticRegression\n",
    "lr_grid_search = GridSearchCV(LogisticRegression(random_state=78), param_grid_lr, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "lr_grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model after GridSearchCV\n",
    "lr_optimized = lr_grid_search.best_estimator_\n",
    "\n",
    "# Log results for the optimized Logistic Regression model\n",
    "predictions_lr_optimized = lr_optimized.predict(X_test_scaled)\n",
    "accuracy_lr_optimized = accuracy_score(y_test, predictions_lr_optimized)\n",
    "cm_lr_optimized = confusion_matrix(y_test, predictions_lr_optimized)\n",
    "cm_df_lr_opt = pd.DataFrame(cm_lr_optimized, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "classification_rep_lr_opt = classification_report(y_test, predictions_lr_optimized)\n",
    "\n",
    "# Log the results of the  optimized Logistic Regression Model to csv\n",
    "log_results_to_csv('LogisticRegression_Optimized', lr_grid_search.best_params_, accuracy_lr_optimized, cm_df_lr_opt, classification_rep_lr_opt, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model 3: Decision Tree Classifier ---\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=78)\n",
    "dt_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions and evaluate model\n",
    "predictions_dt = dt_model.predict(X_test_scaled)\n",
    "accuracy_dt = accuracy_score(y_test, predictions_dt)\n",
    "cm_dt = confusion_matrix(y_test, predictions_dt)\n",
    "cm_df_dt = pd.DataFrame(cm_dt, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "classification_rep_dt = classification_report(y_test, predictions_dt)\n",
    "\n",
    "# Log the results of the Decision Tree Classifier model to csv\n",
    "log_results_to_csv('DecisionTreeClassifier', {'max_depth': None}, accuracy_dt, cm_df_dt, classification_rep_dt, None)\n",
    "\n",
    "# --- Model 3.5: Decision Tree Classifier Optimized ---\n",
    "\n",
    "# Hyperparameter grid for DecisionTreeClassifier\n",
    "param_grid_dt = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [None, 2, 5, 10],\n",
    "    'min_samples_leaf': [None, 1, 2, 4],\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# GridSearchCV for DecisionTreeClassifier\n",
    "dt_grid_search = GridSearchCV(DecisionTreeClassifier(random_state=78), param_grid_dt, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "dt_grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model after GridSearchCV\n",
    "dt_optimized = dt_grid_search.best_estimator_\n",
    "\n",
    "# Log results for the optimized DecisionTreeClassifier model\n",
    "predictions_dt_optimized = dt_optimized.predict(X_test_scaled)\n",
    "accuracy_dt_optimized = accuracy_score(y_test, predictions_dt_optimized)\n",
    "cm_dt_optimized = confusion_matrix(y_test, predictions_dt_optimized)\n",
    "cm_df_dt_opt = pd.DataFrame(cm_dt_optimized, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "classification_rep_dt_opt = classification_report(y_test, predictions_dt_optimized)\n",
    "\n",
    "# Log results for the optimized DecisionTreeClassifier model to csv\n",
    "log_results_to_csv('DecisionTreeClassifier_Optimized', dt_grid_search.best_params_, accuracy_dt_optimized, cm_df_dt_opt, classification_rep_dt_opt, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 4. SVC/SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model 4: SVM Model ---\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(random_state=78)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions and evaluate model\n",
    "predictions_svm = svm_model.predict(X_test_scaled)\n",
    "accuracy_svm = accuracy_score(y_test, predictions_svm)\n",
    "cm_svm = confusion_matrix(y_test, predictions_svm)\n",
    "cm_df_svm = pd.DataFrame(cm_svm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "classification_rep_svm = classification_report(y_test, predictions_svm)\n",
    "\n",
    "# Log the results of the SVM Model to csv\n",
    "log_results_to_csv('SVC', {'kernel': 'rbf'}, accuracy_svm, cm_df_svm, classification_rep_svm, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 5. KNearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model 5: KNNeighbors Model ---\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions and evaluate model\n",
    "predictions_knn = knn_model.predict(X_test_scaled)\n",
    "accuracy_knn = accuracy_score(y_test, predictions_knn)\n",
    "cm_knn = confusion_matrix(y_test, predictions_knn)\n",
    "cm_df_knn = pd.DataFrame(cm_knn, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "classification_rep_knn = classification_report(y_test, predictions_knn)\n",
    "\n",
    "# Log the results of the KNN Model to csv\n",
    "log_results_to_csv('KNN', {'n_neighbors': 5}, accuracy_knn, cm_df_knn, classification_rep_knn, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 6. GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model 6: Naive Bayes/GaussianNB Model ---\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions and evaluate model\n",
    "predictions_nb = nb_model.predict(X_test_scaled)\n",
    "accuracy_nb = accuracy_score(y_test, predictions_nb)\n",
    "cm_nb = confusion_matrix(y_test, predictions_nb)\n",
    "cm_df_nb = pd.DataFrame(cm_nb, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "classification_rep_nb = classification_report(y_test, predictions_nb)\n",
    "\n",
    "# Log the results of the GaussianNB Model to csv\n",
    "log_results_to_csv('GaussianNB', {}, accuracy_nb, cm_df_nb, classification_rep_nb, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 7. Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model 7: Gradient Boosting Model ---\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_model = GradientBoostingClassifier(random_state=78)\n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions and evaluate model\n",
    "predictions_gb = gb_model.predict(X_test_scaled)\n",
    "accuracy_gb = accuracy_score(y_test, predictions_gb)\n",
    "cm_gb = confusion_matrix(y_test, predictions_gb)\n",
    "cm_df_gb = pd.DataFrame(cm_gb, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "classification_rep_gb = classification_report(y_test, predictions_gb)\n",
    "\n",
    "# Log the results of the Gradient Boosting Model to csv\n",
    "log_results_to_csv('GradientBoostingClassifier', {}, accuracy_gb, cm_df_gb, classification_rep_gb, None)\n",
    "\n",
    "# --- Model 7.5: Optimized Gradient Boosting Model ---\n",
    "\n",
    "# Hyperparameter grid for GradientBoostingClassifier\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'learning_rate': [0.01, 0.1, 0.5, 1],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# GridSearchCV for GradientBoostingClassifier\n",
    "gb_grid_search = GridSearchCV(GradientBoostingClassifier(random_state=78), param_grid_gb, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "gb_grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model after GridSearchCV\n",
    "gb_optimized = gb_grid_search.best_estimator_\n",
    "\n",
    "# Log results for the optimized GBC model\n",
    "predictions_gb_optimized = gb_optimized.predict(X_test_scaled)\n",
    "accuracy_gb_optimized = accuracy_score(y_test, predictions_gb_optimized)\n",
    "cm_gb_optimized = confusion_matrix(y_test, predictions_gb_optimized)\n",
    "cm_df_gb_opt = pd.DataFrame(cm_gb_optimized, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "classification_rep_gb_opt = classification_report(y_test, predictions_gb_optimized)\n",
    "\n",
    "# Log results for the optimized GBC model to csv\n",
    "log_results_to_csv('GradientBoostingClassifier_Optimized', gb_grid_search.best_params_, accuracy_gb_optimized, cm_df_gb_opt, classification_rep_gb_opt, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 8. AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model 8: AdaBoost Classifier ---\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ab_model = AdaBoostClassifier(random_state=78)\n",
    "ab_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions and evaluate model\n",
    "predictions_ab = ab_model.predict(X_test_scaled)\n",
    "accuracy_ab = accuracy_score(y_test, predictions_ab)\n",
    "cm_ab = confusion_matrix(y_test, predictions_ab)\n",
    "cm_df_ab = pd.DataFrame(cm_ab, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "classification_rep_ab = classification_report(y_test, predictions_ab)\n",
    "\n",
    "# Log the results of the AdaBoost Model to csv\n",
    "log_results_to_csv('AdaBoostClassifier', {}, accuracy_ab, cm_df_ab, classification_rep_ab, None)\n",
    "\n",
    "# --- Model 8.5: AdaBoost Classifier Optimized ---\n",
    "\n",
    "# Hyperparameter grid for AdaBoostClassifier\n",
    "param_grid_ab = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "# GridSearchCV for AdaBoostClassifier\n",
    "ab_grid_search = GridSearchCV(AdaBoostClassifier(random_state=78), param_grid_ab, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "ab_grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model after GridSearchCV\n",
    "ab_optimized = ab_grid_search.best_estimator_\n",
    "\n",
    "# Log results for the optimized AdaBoost model\n",
    "predictions_ab_optimized = ab_optimized.predict(X_test_scaled)\n",
    "accuracy_ab_optimized = accuracy_score(y_test, predictions_ab_optimized)\n",
    "cm_ab_optimized = confusion_matrix(y_test, predictions_ab_optimized)\n",
    "cm_df_ab_opt = pd.DataFrame(cm_ab_optimized, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "classification_rep_ab_opt = classification_report(y_test, predictions_ab_optimized)\n",
    "\n",
    "# Log the results of the AdaBoost Optimized Model to csv\n",
    "log_results_to_csv('AdaBoostClassifier_Optimized', ab_grid_search.best_params_, accuracy_ab_optimized, cm_df_ab_opt, classification_rep_ab_opt, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 9. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model 9: XGBoost Model ---\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(random_state=78)\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions and evaluate model\n",
    "predictions_xgb = xgb_model.predict(X_test_scaled)\n",
    "accuracy_xgb = accuracy_score(y_test, predictions_xgb)\n",
    "cm_xgb = confusion_matrix(y_test, predictions_xgb)\n",
    "cm_df_xgb = pd.DataFrame(cm_xgb, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "classification_rep_xgb = classification_report(y_test, predictions_xgb)\n",
    "\n",
    "# Log the results of the XGBoost Model to csv\n",
    "log_results_to_csv('XGBoostClassifier', {}, accuracy_xgb, cm_df_xgb, classification_rep_xgb, None)\n",
    "\n",
    "# --- Model 9.5: XGBoost Model Optimized ---\n",
    "\n",
    "# Hyperparameter grid for XGBoost\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# GridSearchCV for XGBoost\n",
    "xgb_grid_search = GridSearchCV(xgb.XGBClassifier(random_state=78), param_grid_xgb, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "xgb_grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model after GridSearchCV\n",
    "xgb_optimized = xgb_grid_search.best_estimator_\n",
    "\n",
    "# Log results for the optimized XGBoost model\n",
    "predictions_xgb_optimized = xgb_optimized.predict(X_test_scaled)\n",
    "accuracy_xgb_optimized = accuracy_score(y_test, predictions_xgb_optimized)\n",
    "cm_xgb_optimized = confusion_matrix(y_test, predictions_xgb_optimized)\n",
    "cm_df_xgb_opt = pd.DataFrame(cm_xgb_optimized, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "classification_rep_xgb_opt = classification_report(y_test, predictions_xgb_optimized)\n",
    "\n",
    "# Log the results of the XGBoost Optimized Model to csv\n",
    "log_results_to_csv('XGBoostClassifier_Optimized', xgb_grid_search.best_params_, accuracy_xgb_optimized, cm_df_xgb_opt, classification_rep_xgb_opt, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 10. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model 10: LightGBM Model ---\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(random_state=78)\n",
    "lgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions and evaluate model\n",
    "predictions_lgb = lgb_model.predict(X_test_scaled)\n",
    "accuracy_lgb = accuracy_score(y_test, predictions_lgb)\n",
    "cm_lgb = confusion_matrix(y_test, predictions_lgb)\n",
    "cm_df_lgb = pd.DataFrame(cm_lgb, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "classification_rep_lgb = classification_report(y_test, predictions_lgb)\n",
    "\n",
    "# Log the results of the LightGBM Model to csv\n",
    "log_results_to_csv('LightGBMClassifier', {}, accuracy_lgb, cm_df_lgb, classification_rep_lgb, None)\n",
    "\n",
    "# --- Model 10.5: Optimized LightGBM Model ---\n",
    "\n",
    "# Hyperparameter grid for LightGBM\n",
    "param_grid_lgb = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'num_leaves': [31, 50, 100]\n",
    "}\n",
    "\n",
    "# GridSearchCV for LightGBM\n",
    "lgb_grid_search = GridSearchCV(lgb.LGBMClassifier(random_state=78), param_grid_lgb, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "lgb_grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model after GridSearchCV\n",
    "lgb_optimized = lgb_grid_search.best_estimator_\n",
    "\n",
    "# Log results for the optimized LightGBM model\n",
    "predictions_lgb_optimized = lgb_optimized.predict(X_test_scaled)\n",
    "accuracy_lgb_optimized = accuracy_score(y_test, predictions_lgb_optimized)\n",
    "cm_lgb_optimized = confusion_matrix(y_test, predictions_lgb_optimized)\n",
    "cm_df_lgb_opt = pd.DataFrame(cm_lgb_optimized, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "classification_rep_lgb_opt = classification_report(y_test, predictions_lgb_optimized)\n",
    "\n",
    "# Log results for the optimized LightGBM model to csv\n",
    "log_results_to_csv('LightGBMClassifier_Optimized', lgb_grid_search.best_params_, accuracy_lgb_optimized, cm_df_lgb_opt, classification_rep_lgb_opt, None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
